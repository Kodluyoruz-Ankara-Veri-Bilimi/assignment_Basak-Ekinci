{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report ,r2_score, mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ind_18      ind_37   ind_239     ind_241    ind_311    ind_327  \\\n",
      "0      9.1100  184.819232  0.000217   99.736250  97.980028  12.056738   \n",
      "1      9.2225  191.985663  0.000217   99.668519  97.932319  11.971831   \n",
      "2      9.3125  197.993551  0.000217   99.627319  97.910664  11.888112   \n",
      "3      9.4150  200.370912  0.000217   99.567128  97.870334  11.805556   \n",
      "4      9.8925  223.561880  0.000217   99.380024  97.705214  11.724138   \n",
      "...       ...         ...       ...         ...        ...        ...   \n",
      "6162  16.2175  102.453252  0.000013  100.965196  98.839946  14.583333   \n",
      "6163  16.1175   96.780546  0.000013  100.960612  98.837255  14.285714   \n",
      "6164  16.3125  108.218518  0.000013  100.885130  98.765154  14.000000   \n",
      "6165  16.4200  124.933707  0.000013  100.783022  98.666984  13.725490   \n",
      "6166  16.4500  123.289457  0.000013  100.824169  98.709061  13.461538   \n",
      "\n",
      "      20_target  \n",
      "0     15.135802  \n",
      "1     15.143348  \n",
      "2     15.146870  \n",
      "3     15.153283  \n",
      "4    -15.179065  \n",
      "...         ...  \n",
      "6162  14.673247  \n",
      "6163  14.673750  \n",
      "6164 -14.684566  \n",
      "6165 -14.699280  \n",
      "6166 -14.693117  \n",
      "\n",
      "[6167 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel (\"HW_Data_Set.xlsx\", usecols = ['ind_37','ind_311','ind_239','ind_241','ind_18','ind_327','20_target'])\n",
    "print (df)\n",
    "#Alacağım değişkenleri random forest yaptıktan sonra, importance değerine bakarak seçtim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('20_target', 1)\n",
    "y =df['20_target']\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,y,test_size = 0.3, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X,y,test_size = 0.3, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basak/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.431846412563441"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_model = MLPRegressor(hidden_layer_sizes=(100,20)).fit(X_train_scaled,y_train)\n",
    "y_pred = mlp_model.predict(X_test_scaled)\n",
    "np.sqrt(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y,y_pred))\n",
    "confusion_mat = confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mlp_params = {\n",
    "    'alpha':[0.1,0.01,0.02,0.005],\n",
    "    'hidden_layer_sizes': [(20,20),(100,50,150),(300,200,150)],\n",
    "    'activation': ['relu','logistic']\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_cv_model = GridSearchCV(mlp_model, mlp_params, cv = 10, n_jobs=-1, verbose =2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 30.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 50.9min finished\n",
      "/home/basak/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(100, 20),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=200, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=None, shuffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'activation': ['relu', 'logistic'],\n",
       "                         'alpha': [0.1, 0.01, 0.02, 0.005],\n",
       "                         'hidden_layer_sizes': [(20, 20), (100, 50, 150),\n",
       "                                                (300, 200, 150)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_cv_model.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametlerler: {'activation': 'logistic', 'alpha': 0.02, 'hidden_layer_sizes': (20, 20)}\n"
     ]
    }
   ],
   "source": [
    "print(\"En iyi parametlerler: \" + str(mlp_cv_model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tuned=MLPRegressor(alpha= 0.02,activation=\"logistic\",hidden_layer_sizes=(20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/basak/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.02, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(20, 20), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_tuned.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS BEFORE  THE TUNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "MLPRegressor:\n",
      "mean_squared_error: 2615.7360291209743\n"
     ]
    }
   ],
   "source": [
    "modeller = [\n",
    "   mlp_model\n",
    "]\n",
    "\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)     \n",
    "    dogruluk = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "    print(\"-\"*28)\n",
    "    print(isimler + \":\" )\n",
    "    print(\"mean_squared_error:\", dogruluk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS AFTER  THE TUNE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "MLPRegressor:\n",
      "mean_squared_error: 14.681666028090989\n"
     ]
    }
   ],
   "source": [
    "modeller = [\n",
    "    mlp_tuned\n",
    "]\n",
    "\n",
    "\n",
    "for model in modeller:\n",
    "    isimler = model.__class__.__name__\n",
    "    y_pred = model.predict(X_test)     \n",
    "    dogruluk = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "    print(\"-\"*28)\n",
    "    print(isimler + \":\" )\n",
    "    print(\"mean_squared_error:\", dogruluk)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
