{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Information():\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Information object created\")\n",
    "        self.df = pd.read_csv(\"hmelq.csv\")\n",
    "        \n",
    "    def info(self): \n",
    "        \n",
    "         \n",
    "        print(self.df.head())\n",
    "        print(\"--------------------\")\n",
    "        print(self.df.sample(30))#random row and columns\n",
    "        print(\"--------------------\")\n",
    "        print(self.df.describe())#give the count,mean and data number\n",
    "        print(\"--------------------\")\n",
    "        print(self.df.info())#give the non values\n",
    "        print(\"------Drop the rows where at least one element is missing----------\")\n",
    "        print(self.df.dropna().head())##nan değerleri temizlenmesi,Drop the rows where at least one element is missing:\n",
    "        # badlerin dağılımlarının sayısı\n",
    "          #tb.index=[\"0=False\",\"1=True\"]\n",
    "        self.tb1=pd.crosstab(index=self.df[\"bad\"],columns=\"Count\")\n",
    "        print(\"------Distribution number of Bad----------\")\n",
    "        print(self.tb1)##nan değerleri temizlenmesi,Drop the rows where at least one element is missing:\n",
    "        print(\"------Distribution number of the job according to bad----------\")\n",
    "        \n",
    "        self.tb_bad_job=pd.crosstab(index=self.df[\"job\"],columns=self.df[\"bad\"],margins=True)\n",
    "        print(self.tb_bad_job)\n",
    "        \n",
    "        \n",
    "#        print(self.tb1)##nan değerleri temizlenmesi,Drop the rows where at least one element is missing:\n",
    "#jobların 0 ve 1 e göre dağılımları\n",
    "#tb_bad_job=pd.crosstab(index=df[\"job\"],columns=df[\"bad\"],margins=True)\n",
    "#tb_bad_job\n",
    "#This compares the index and column to get the count.\n",
    "class Visualizer:\n",
    "    \n",
    "        def __init__(self):\n",
    "            print(\"Visualizer object created!\")  \n",
    "            self.df = pd.read_csv(\"hmelq.csv\")\n",
    "       \n",
    "                \n",
    "        def histogram(self): \n",
    "\n",
    "        #tüm nümeriklerin histogram grafikleri\n",
    "             for i in self.df.columns:\n",
    "                 if (i!='reason' and i!='job' and i!='bad'):\n",
    "                        plt.figure()\n",
    "                        plt.hist(self.df[i],bins=100,color=\"orange\")\n",
    "                        plt.title(\"Histogram of \" + i)\n",
    "        def hist(self): \n",
    "            pd.DataFrame(self.df).plot.hist()\n",
    "            plt.show()\n",
    "            \n",
    "        def corelation(self): \n",
    "            corr = self.df.corr()\n",
    "            print(corr)  \n",
    "            fig, ax=plt.subplots(figsize=(10,8))\n",
    "            colormap =sns.diverging_palette(220,10,as_cmap=True)\n",
    "            sns.heatmap(corr,cmap=colormap, annot=True, fmt='.2f')\n",
    "            plt.xticks(range(len(corr.columns)),corr.columns)\n",
    "            plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "            plt.show() \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "class PreprocessStrategy():\n",
    " \n",
    "       def __init__(self):\n",
    "        print(\"done\")  \n",
    "        self.df = pd.read_csv(\"hmelq.csv\")\n",
    "        self.df2 = pd.read_excel (\"HW_Data_Set.xlsx\", usecols = ['ind_424','ind_426','ind_428', '20_target'])\n",
    "\n",
    "    ##tüm nümerik değerlerde bad'in 0 ve 1 olduğu durumlar için shapiro testi\n",
    "    \n",
    "       def gaussiandist(self): \n",
    "        grps=pd.unique(self.df.bad.values)\n",
    "        grps\n",
    "        alpha=0.05\n",
    "        for i in self.df.columns:\n",
    "                if (i!='reason' and i!='job' and i!='bad'): #i'nin reason, job, ve bad olmadığı durumlarda çalış \n",
    "                    for name in grps:\n",
    "                        stat,p=shapiro(self.df[i][self.df['bad']==name])\n",
    "                        print(i)\n",
    "                        print(name,\"için İstatistik değeri: %.3f, p değeri =\" %stat , p)        \n",
    "                        if p >alpha:\n",
    "                             print('Orneklem Normal (Gaussian) dağılımdan gelmektedir')  \n",
    "                        else:\n",
    "                             print('Orneklem Normal (Gaussian) dağılım gostermemektedir')\n",
    "                                \n",
    "                                \n",
    "                                       \n",
    "        #burada ..... değişkenlerinin bad üzerinde etkili bir değişken olup olmadığı bulunmaktadır.\n",
    "    def ttest(self):\n",
    "    for i in self.df.columns:\n",
    "           if (i!='reason' and i!='job' and i!='bad'):\n",
    "                stat,p = levene(self.df[i][self.df['bad'] == 0],\n",
    "               self.df[i][self.df['bad'] == 1]) \n",
    "        print(\"\\n\",i,\"için istatistik değeri: %.3f ve p değeri =\" %stat , p)#equal variance test\n",
    "        alpha=0.05\n",
    "        if p >alpha:\n",
    "            print('Orneklem Sabit varyansa(constant variance) sahiptir)')\n",
    "            const=True\n",
    "        else:\n",
    "            print('Orneklem Sabit varyansa(constant variance) sahip değildir')\n",
    "            const=False\n",
    "        ##aynı döngü içinde ttest yaptım, constant varyansı levene ile aldım(const)\n",
    "        s,p =stats.mannwhitneyu(self.df[i][self.df['bad'] == 0],\n",
    "               self.df[i][self.df['bad'] == 1])\n",
    "        print(\"F_oneway istatistik değeri: %.3f ve p değeri =\" %s , p)\n",
    "        if p < 0.05:\n",
    "            print(\"Bu veri etkili bir değişkendir (H0 = reject)\")\n",
    "        else:\n",
    "            print(\"Bu veri etkili bir değişken değildir (H0 = fail to reject)\")                        \n",
    "         \n",
    "\n",
    "          Prepare the data for training\n",
    "                       \n",
    "      \n",
    "       def Preparethedata(self):      \n",
    "            X = self.df[['ind_424', 'ind_426', 'ind_428']]    \n",
    "            y =self.df['20_target']                       \n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=5)\n",
    "            print(X_train.shape)\n",
    "            print(X_test.shape)\n",
    "            print(Y_train.shape)\n",
    "            print(Y_test.shape)            \n",
    "    \n",
    "\n",
    "##       Train the model using sklearn LinearRegression\n",
    "            \n",
    "        def LinearRegression(self):      \n",
    "            lin_model = LinearRegression()\n",
    "            lin_model.fit(X_train, Y_train)        \n",
    "                \n",
    "                \n",
    "# model evaluation for training set                \n",
    "        def evaluation(self):       \n",
    "            y_train_predict = lin_model.predict(X_train)\n",
    "            rmse = (np.sqrt(mean_squared_error(Y_train, y_train_predict)))\n",
    "            r2 = r2_score(Y_train, y_train_predict)\n",
    "\n",
    "            print(\"The model performance for training set\")\n",
    "            print(\"--------------------------------------\")\n",
    "            print('RMSE is {}'.format(rmse))\n",
    "            print('R2 score is {}'.format(r2))\n",
    "            print(\"\\n\")\n",
    "\n",
    "# model evaluation for testing set\n",
    "\n",
    "           y_test_predict = lin_model.predict(X_test)\n",
    "# root mean square error of the model\n",
    "           rmse = (np.sqrt(mean_squared_error(Y_test, y_test_predict)))\n",
    "\n",
    "# r-squared score of the model\n",
    "          r2 = r2_score(Y_test, y_test_predict)\n",
    "\n",
    "           print(\"The model performance for testing set\")\n",
    "           print(\"--------------------------------------\")\n",
    "            print('RMSE is {}'.format(rmse))\n",
    "            print('R2 score is {}'.format(r2))\n",
    "       \n",
    "                \n",
    "        def straightline(self):       \n",
    "# plotting the y_test vs y_pred\n",
    "# ideally should have been a straight line\n",
    "          plt.scatter(Y_test, y_test_predict)\n",
    "          plt.show()\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "  \n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PreprocessStrategy' object has no attribute 'Preparethedata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-51c0aceffcab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPreprocessStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPreparethedata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PreprocessStrategy' object has no attribute 'Preparethedata'"
     ]
    }
   ],
   "source": [
    "result=PreprocessStrategy()\n",
    "result.Preparethedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-629914d6d1c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
